{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neutrino interactions 1. Week 8\n",
    "\n",
    "This project aims to teach some basic principles of *data analysis* particularly in the context of so-called *big data*. The particular problem to be addressed is one of **classification** where *instances* of 2 particular classes of data require separation. Whilst the specific problem deals with a problem in particle physics the methods and techniques employed can be applied, equally, to data from many sources, e.g. financial, medical, biosciences, socialology, etc.\n",
    "\n",
    "The following plot was presented by the ATLAS collaboration at CERN as proof of the discovery of the Higgs Boson. It shows 2 classes of data, namely the *Higgs Boson signal* (red) and *backgrounds* (blue and purple). This was the result of a complicated analysis that looked for Higgs boson decay into 4 leptons. In such an analysis you want to reduce the *background* events to as few as possible whilst keeping as many *signal* events as possible.\n",
    "\n",
    "<img src=\"Higgs.png\" width=500>\n",
    "\n",
    "A simple way of approaching such an analysis would be to find a set of *variables* or *parameters* that represent features in the 2 classes of events (signal and background), look for those variables/parameters which provide some *discrimination* between the 2 event classes and place cuts on those variables - keeping events that 'pass' the cuts and throwing the others away. This is a simple *linear cuts* based analysis. Usually the cut is placed on a variable/parameter in a way in which some *metric* is maximised or minimised.\n",
    "\n",
    "## Cut placement and metrics\n",
    "\n",
    "The plot below shows an idealised situation where a variable that represents some feature of 2 classes of events (**class A**=red, **class B**=green, **B** is to be kept) is plotted. In this case it is very clear to see by eye that, by placing a cut at around **x=1.0** and keeping all events to the right of that cut will keep **all** of the events in **class B** and discard **all** of the events in **class A**.\n",
    "\n",
    "<img src=\"ideal.png\" width=500>\n",
    "\n",
    "In reality it is highly unusual (impossible?) to find a variable with such a high *discriminating power*, the following plot is more realistic and is one of those (**nue**) that you will be considering today.\n",
    "\n",
    "<img src=\"nue.png\" width=500>\n",
    "\n",
    "This variable clearly gives some *discrimination* between the 2 event classes. Even by eye it can be seen that cutting at a value of at around **2000** for example, and keeping all events to the right of that cut, will significantly reduce the number of **class A** events whilst keeping *most* (not all) of the **class B** events. However, we need to be more methodical than just placing a cut by eye, so typically a suitable *metric* is used.\n",
    "\n",
    "In this project we will seek to maximise the product **efficiency ($\\epsilon$) $\\times$ purity($\\rho$)** where these are defined as:\n",
    "\n",
    "$$ \\epsilon = \\frac{\\rm{Number\\:of\\:A\\:events\\:kept}}{\\rm{Total\\:number\\:of\\:A\\:events}} $$\n",
    "\n",
    "$$ \\rho = \\frac{\\rm{Number\\:of\\:A\\:events\\:kept}}{\\rm{(Number\\:of\\:A\\:events\\:+\\:Number\\:of\\:B\\:events)\\:kept}} $$\n",
    "\n",
    "By calculating the product of $\\epsilon\\times\\rho$ as a function of each variable in question it will be possible to determine exactly where the cut should be placed in order to optimise the cut. **Note:** care is needed here, the calculation is done differently if the cut is to keep events to the *left* of the cut or the *right* of the cut. Examples of $\\epsilon\\times\\rho$ for a cut keeping everything to the left (1st plot) or keeping everything to the right (2nd plot) of the **nue** variable above are given below.\n",
    "\n",
    "<img src=\"nue_above.png\" width=500>\n",
    "\n",
    "<img src=\"nue_below.png\" width=500>\n",
    "\n",
    "The first plot basically tells you that there is no good cut which keeps everything to the left of the cut but a cut at around 2000 (the exact value can be determined exactly from the data which has made the $\\epsilon\\times\\rho$ curve) will be effective and efficient. \n",
    "\n",
    "Where event **classification** takes place it is usual practise to use *training samples* to determine where the cuts are placed and, once the cuts are optimised, to run the cuts on a true set of data.\n",
    "\n",
    "In principle, in the case of a *linear cuts analaysis* the correct way to proceed is as follows:\n",
    "\n",
    "* choose a cut that has known discriminating power\n",
    "* optimise the cut position(s) using a suitable metric\n",
    "* apply the cut to the training data sets\n",
    "* move onto the next cut and repeat\n",
    "\n",
    "In other words, not all cuts are optimised at the same time. It is possible to optimise a set of cuts and apply them to the data all at the same time however this approach will almost certainly give you a worse result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Neutrino events\n",
    "\n",
    "In this project we will perform an analysis of events produced when a neutrino interacts with a nucleon. There are a number of different *interaction types* that can take place. The generic Feynman diagrams for these interactions are given below.\n",
    "\n",
    "<img src=\"nuint.png\" width=500>\n",
    "\n",
    "The challenge here is to select the so-called *RES* (resonant production) class of events from all other event types whilst maximising the product **efficiency ($\\epsilon$) $\\times$ purity($\\rho$)**. Note that some variables may benefit from 2 cuts being placed (one in each \"direction\").\n",
    " \n",
    "\n",
    "## Week 8 Tasks\n",
    "\n",
    "Inside your data folder you will find 4 files called *signal_training.dat*, *background_training.dat*, *signal_data.dat*, *background_data.dat*. The first 2 files correspond to the training samples for the Class A (RES) events and Class B (others) events respectively. There several variables that describe the events in each file these are described in the Appendix at the bottom of these notes.\n",
    "\n",
    "Note that, in some cases a variable is not defined for a particular event, in that case, the figure -999.0 is entered instead. The variables with the *true* word in them, should not be used in your classification!\n",
    "\n",
    "The data and training sets each have 10000 events in them. Start off with the training sets only\n",
    "\n",
    "1. First inspect all 19 variables and plot histograms for the *signal* and the *background* in different colours. Do not include in your histograms the value -999. Write down the fraction of events where the variable is not defined for signal and background.\n",
    "2. By eye identify the variables that have good, intermediate and poor discrimination\n",
    "3. For each of the variables, apply a selection cut using the ($\\epsilon\\times\\rho$) metric. Write a table with four columns: (i) variable name, (ii) maximum value of ($\\epsilon\\times\\rho$), (iii) selection cut value, (iv) good/intermediate/poor discriminator\n",
    "4. How could you treat the -999. values? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "267958191c64ef44b0a95e93d547012edd1ca102"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "aa99042247599852a5dc8719eb154cbf809b0d65"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 402
      }
     }
    },
    {
     "data": {
      "image/png": "487b30d08c8fffd5c97ee040a74fb3eebeaf541f"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 399
      }
     }
    },
    {
     "data": {
      "image/png": "ee1a429765dae9bca163569b5566a6b3f0d61268"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "4e6463521586259ded0ecbf45176a0c415b7d199"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 390
      }
     }
    },
    {
     "data": {
      "image/png": "9538eeb741b2d18792f23092bb05049e26ed6921"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "8ae8656d4eabdddc80e1966994a86b4520c498cb"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "1b66db3672b98d2dcccbdfdd90c84f02e0860b6c"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "8e20f5c0aa0367c22af95581a4cb8cdd4a888d8c"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 390
      }
     }
    },
    {
     "data": {
      "image/png": "40c9753636f7a3afe95d60275064eded1a35c541"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 394
      }
     }
    },
    {
     "data": {
      "image/png": "3cf3eb68908a7d897e19adee0d30ba0c90a82ef7"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "274554d8267c3a68e068c2f5b028b29890786827"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "87b119e039819d5b8712ada6656acbdae6674a3e"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "7e948b409f7707f33e3064298d18676f2ff143d4"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 402
      }
     }
    },
    {
     "data": {
      "image/png": "542f154c0f932e1d9f20644290a2ad9368c672d0"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "a38be726e68e64e13955d0455bba47f62d3db32e"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "a265153546e1d9e23e75c1dc6ceefc68add428a6"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "0aca9667d2aef1447fd8b486c326df00096a993e"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    },
    {
     "data": {
      "image/png": "8258e2c601f1813adac36a1bb11213bf92ba029d"
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 397
      }
     }
    }
   ],
   "source": [
    "#Task 1\n",
    "signal = pd.read_csv('../data/signal_data.dat', sep = \" \")\n",
    "background = pd.read_csv('../data/background_data.dat', sep = \" \")\n",
    "\n",
    "sigframe = DataFrame(signal)\n",
    "bacframe = DataFrame(background)\n",
    "fulldatanames = list(signal.keys())\n",
    "dataname = list(signal.keys())[3:]\n",
    "\n",
    "for i in dataname:\n",
    "    sigframe[sigframe[i]>-999.].loc[:,i].hist(alpha = 0.5, label = 'Signal')\n",
    "    bacframe[bacframe[i]>-999.].loc[:,i].hist(alpha = 0.5, label = 'Background')\n",
    "    plt.title(i)\n",
    "    plt.xlabel((i, 'value')) # This is close enough for now\n",
    "    plt.ylabel('Occurences')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Task 2\n",
    "#\n",
    "# I, P, P, I, P, P, P, P, P, P, I, G, G, P, I, P, G, G, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Max (Eps X Rho)</th>\n",
       "      <th>Best cut</th>\n",
       "      <th>Discriminator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>muonmom</td>\n",
       "      <td>0.494973</td>\n",
       "      <td>9939</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>muoncos</td>\n",
       "      <td>0.479480</td>\n",
       "      <td>-1</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muonpull</td>\n",
       "      <td>0.494439</td>\n",
       "      <td>6</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ntracks</td>\n",
       "      <td>0.555651</td>\n",
       "      <td>0</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negpionmom</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>3038</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pospions</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>-1</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pospionmom</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>31107</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pospiontheta</td>\n",
       "      <td>0.471881</td>\n",
       "      <td>1</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pospionz</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>440</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pi0elpull</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>1</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>piontotale</td>\n",
       "      <td>0.561636</td>\n",
       "      <td>119</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>energybalance</td>\n",
       "      <td>0.601058</td>\n",
       "      <td>-52</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nue</td>\n",
       "      <td>0.646019</td>\n",
       "      <td>2160</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>muonpos</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>2822</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>muonz</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>-161</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fgdcos</td>\n",
       "      <td>0.476431</td>\n",
       "      <td>1</td>\n",
       "      <td>Poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>effpullx</td>\n",
       "      <td>0.653733</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>effpully</td>\n",
       "      <td>0.741482</td>\n",
       "      <td>0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>efftime</td>\n",
       "      <td>0.546136</td>\n",
       "      <td>1</td>\n",
       "      <td>Intermediate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 3\n",
    "def expval(nA, nAkeep, nBkeep):\n",
    "    \"\"\"returns value of Eps X Rho (Efficiency * Purity)\"\"\"\n",
    "    eff = nAkeep/nA\n",
    "    try:                                     # Yes, we're doing this again\n",
    "        pur = nAkeep / (nAkeep + nBkeep)\n",
    "    except ZeroDivisionError:\n",
    "        pur = 0\n",
    "    return(eff*pur)\n",
    "\n",
    "def fullExPcalc(frame1, frame2, datanames, dir_, quickrun = 0, debug = 0): # I had to write this twice, cos cocalc, so you'd better like it\n",
    "    \"\"\"Calculates the max (Eps X Rho) values, and their cuts positions, for a pair of data frames, and outputs them as lists\"\"\"\n",
    "    expmaxlist = []\n",
    "    cutmaxlist = []\n",
    "    # Attempt to automate the range of the cuts. This seems to slow the program down vs just setting a sensible (but small) range, but allows for more general application\n",
    "    for datacnt in range(len(datanames)): # Produces 2 pandas series (maxima & minima)\n",
    "        cutmaxser = frame1.max(axis = 0)\n",
    "        cutminser = frame1[frame1>-999].min(axis = 0)\n",
    "\n",
    "    for i in datanames:\n",
    "        if debug == 2: # To check datanames are being read correctly\n",
    "            print(i)\n",
    "            print(datanames)\n",
    "        elif debug == 3:\n",
    "            print(i)\n",
    "        expmax = 0\n",
    "        nA = len(frame1[i])\n",
    "\n",
    "        datacnt = datanames.index(i)\n",
    "        cutmax = int(cutmaxser[datacnt]) + 1 # Avoids cutting off the actual max/min due to rounding down/up\n",
    "        cutmin = int(cutminser[datacnt]) - 1\n",
    "        if quickrun == 1: # Time saving option, reduces precision. Could definitely be written better, but I don't feel like working out how to get the order of a value\n",
    "            totrange = (abs(cutmax) + abs(cutmin))\n",
    "            if totrange < 10:\n",
    "                step = 1\n",
    "            elif totrange < 100:\n",
    "                step = int(totrange/10)\n",
    "            elif totrange < 1000:\n",
    "                step = int(totrange/100)\n",
    "            elif totrange < 10000:\n",
    "                step = int(totrange/100)\n",
    "            else:\n",
    "                step = int(totrange/500)\n",
    "        else:\n",
    "            step = 1\n",
    "\n",
    "        for cutval in range(cutmin, cutmax, step):\n",
    "            if dir_ == 'R':\n",
    "                nAkeep = len(frame1[frame1[i]>cutval][i])\n",
    "                nBkeep = len(frame2[frame2[i]>cutval][i])\n",
    "            elif dir_ == 'L':\n",
    "                nAkeep = len(frame1[frame1[i]<cutval][i])\n",
    "                nBkeep = len(frame2[frame2[i]<cutval][i])\n",
    "            else:\n",
    "                \"Invalid direction, use 'R' or 'L'\"\n",
    "\n",
    "            expval_ = expval(nA, nAkeep, nBkeep)\n",
    "\n",
    "            if expval_ > expmax: # Would making this a var then doing this bit be more efficient? Does it store expval(nA, nAkeep, nBkeep)?\n",
    "                expmax = expval_\n",
    "                cutmax = cutval\n",
    "                if debug == 3:\n",
    "                    print('expmax: ', expmax, 'V', expval_, 'cutmax: ', cutmax, 'V', cutval)\n",
    "\n",
    "            if debug == 1: # To check it's outputting correct lengths\n",
    "                print('Dataname: ', i)\n",
    "                print('direction: ',dir_)\n",
    "                print('cutval: ', cutval)\n",
    "                print('nAkeep: ',nAkeep, 'nBkeep: ', nBkeep, 'nA: ', nA)\n",
    "                print('Metric: ', expval(nA, nAkeep, nBkeep))\n",
    "\n",
    "        cutmaxlist.append(cutmax)\n",
    "        expmaxlist.append(expmax)\n",
    "    return(expmaxlist, cutmaxlist)\n",
    "\n",
    "# Changing quickrun to 0 will give more precise results, but takes ages to run (I haven't managed to get it to complete yet)\n",
    "maxlistR, cutlistR = fullExPcalc(sigframe, bacframe, fulldatanames, 'R', quickrun = 0, debug = 0)\n",
    "maxlistL, cutlistL = fullExPcalc(sigframe, bacframe, fulldatanames, 'L', quickrun = 0, debug = 0)\n",
    "\n",
    "# Comparing left and right cut values, taking the best\n",
    "maxlistF, cutlistF = [],[]\n",
    "for i in range (0,len(maxlistR)):\n",
    "    if maxlistR[i] > maxlistL[i]:\n",
    "        maxlistF.append(maxlistR[i])\n",
    "        cutlistF.append(cutlistR[i])\n",
    "    elif maxlistL[i] > maxlistR[i]:\n",
    "        maxlistF.append(maxlistL[i])\n",
    "        cutlistF.append(cutlistL[i])\n",
    "\n",
    "# Cropping off the first 3 columns (I'm assuming this is wanted)\n",
    "newmaxlistF = maxlistF[3:]\n",
    "newcutlistF = cutlistF[3:]\n",
    "\n",
    "# Dictionary things:\n",
    "P, I, G = 'Poor', 'Intermediate', 'Good'\n",
    "discr = [I, P, P, I, P, P, P, P, P, P, I, G, G, P, I, P, G, G, I]\n",
    "tabledata = {'Variable': dataname, 'Max (Eps X Rho)': newmaxlistF, 'Best cut': newcutlistF, 'Discriminator': discr}\n",
    "tableframe = DataFrame(tabledata)\n",
    "\n",
    "display(tableframe)\n",
    "\n",
    "# # Uncommenting this will produce a table without the first 3 columns cropped off\n",
    "#\n",
    "# nulls = [Null, Null, Null]\n",
    "# otherdiscr = nulls.append(discr)\n",
    "# othertabledata = {'Variable': fulldatanames, 'Max (Eps X Rho)': maxlistF, 'Best cut': cutlistF, 'Discriminator': otherdiscr}\n",
    "# othertableframe = DataFrame(othertabledata)\n",
    "#\n",
    "# display(othertableframe)\n",
    "#\n",
    "\n",
    "\n",
    "# Many of these seem like questionable results, but I have no way of knowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Tests:\n",
    "\n",
    "# def testrange(frame1, frame2, datanames, dir_, debug = 0):\n",
    "#     for datacnt in range(len(datanames)):# Attempt to automate the range of the cuts\n",
    "# #             cutmax = max(frame1[datanames])\n",
    "#             cutmax = frame1.max(axis = 0)\n",
    "#             cutmin = frame1[frame1>-999].min(axis = 0)\n",
    "#     return(cutmax, cutmin)\n",
    "\n",
    "# testrange(sigframe, bacframe, fulldatanames, 'R')\n",
    "\n",
    "# sigframe[sigframe[i]>-999.]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print('maxR len', len(maxlistR),'cutR len', len(cutlistR),'maxL len',len(maxlistL),'cutL len', len(cutlistL))\n",
    "# print('maxR', maxlistR,'cutR', cutlistR, 'maxL', maxlistL, 'cutL', cutlistL)\n",
    "\n",
    "# print(len(fulldatanames))\n",
    "# print(len(maxlistF))\n",
    "# print(len(cutlistF))\n",
    "\n",
    "# print(len(dataname))\n",
    "# print(len(newmaxlistF))\n",
    "# print(len(newcutlistF))\n",
    "\n",
    "# dir_='R'\n",
    "\n",
    "# nA = len(sigframe['ntracks'])\n",
    "# for cutval in range(0, 8):\n",
    "#             if dir_ == 'R':\n",
    "#                 nAkeep = len(sigframe[sigframe['ntracks']>cutval]['ntracks'])\n",
    "#                 nBkeep = len(bacframe[bacframe['ntracks']>cutval]['ntracks'])\n",
    "#             elif dir_ == 'L':\n",
    "#                 nAkeep = len(sigframe[sigframe['ntracks']<cutval]['ntracks'])\n",
    "#                 nBkeep = len(bacframe[bacframe['ntracks']<cutval]['ntracks'])\n",
    "#             print(nAkeep, nBkeep)\n",
    "#             print(expval(nA, nAkeep, nBkeep))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#Task 4\n",
    "#\n",
    "#replace them with Nulls (same as the logic at the end of the lecture notes does)\n",
    "#\n",
    "#replace them with the average of the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Appendix - information on the variables in the data\n",
    "\n",
    "### True Variables\n",
    "\n",
    "True variables should **not** be used as discriminators as in the real world data analysers will not have access to these. They are included in the file to help with training by providing different classifier information.\n",
    "\n",
    "* event_true : index of the event in the sample, included for easier reference to specific events.\n",
    "* signal_true : Whether the event is signal (1.0) or background (0.0). \n",
    "* reaction_true : Unique identifier that says what the true reaction was: 0-1 : CCQE; 2 : Resonant; >=3 : Deep inelastic\n",
    "\n",
    "Note: *‘reaction_true’* should be ignored to begin with, but if you have extra time and fancy a challenge, events can be plotted in different histograms according to the reaction type instead of just signal vs background. The true signal definition is defined as **signal_true = (reaction_type == 2)**\n",
    "\n",
    "### Global Variables\n",
    "\n",
    "Global variables are saved for every event that occurs. An example is the time that an event occurs in a detector. These can be used as potential discriminators.\n",
    "\n",
    "* muonmom : Measured muon track momentum\n",
    "* muoncos : Measured muon track angle with respect to the neutrino beam\n",
    "* muonpull : ‘Pulls’ are used to decide how much a track looks like a given particle.  This muonpull is calculated by taking the highest momentum track seen in the detector and deciding how much it looks like a muon.\n",
    "* ntracks : Number of particle tracks observed in one of the detectors.\n",
    "* piontotale : Total summed energy of pion particles\n",
    "* energybalance : Pull calculated from difference in energy between muon and pion tracks\n",
    "* nue : Calculated neutrino energy\n",
    "* pospions : Number of observed positive pions\n",
    "* muonpos : Start position of the muon track\n",
    "* muonz : Length of the muon track\n",
    "* effpullx : Pull calculated from the horizontal size of the event\n",
    "* effpully : Pull calculated from the vertical size of the event  \n",
    "* effpulltime : Pull calculated from the total time of the event\n",
    "\n",
    "### Track Variables\n",
    "In some events there will be additional information available when certain conditions are met. For example, if we observe a positively charged pion track in our detector, we can use the track to calculate the pion momentum and angle. However some events will not observe charged pions, so in that case it is impossible to calculate the momentum and angle for a non-existent pion. \n",
    "\n",
    "This is reflected in the datafile by the number -999.9. In the event building code example these are replaced by  ‘None’ when read in, so that the following conditional can be used:\n",
    "\n",
    "** If no negpionmom is saved for this event don’t cut on that variable **\n",
    "\n",
    "* negpionmom : Momentum of observed negative pion track\n",
    "* pospionmom : Momentum of observed positive pion track\n",
    "* pospiontheta : Angle of observed positive pion track\n",
    "* fgdcos : Related to the angle of the highest momentum track first seen in the event\n",
    "* pi0elpull : Pull variable to decide whether two electron tracks looked like they came from a neutral pion decay.\n",
    "\n",
    "\n",
    " These can be used as potential discriminators.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
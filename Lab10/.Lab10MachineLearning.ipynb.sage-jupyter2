{"backend_state":"running","kernel":"anaconda5","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":75907072},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1557308718603,"exec_count":1,"id":"1a66bf","input":"# Package imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib\n# Display plots inline and change default figure size\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (10.0, 8.0)","kernel":"anaconda5","pos":1,"start":1557308717805,"state":"done","type":"cell"}
{"cell_type":"markdown","exec_count":1,"id":"28375e","input":"### NN Stuff","kernel":"anaconda5","pos":0.5,"state":"done","type":"cell"}
{"cell_type":"markdown","exec_count":13,"id":"53fcdb","input":"### Model Building","kernel":"anaconda5","pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","exec_count":6,"id":"63de80","input":"### Training Stuff","kernel":"anaconda5","pos":5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d7f5d8","input":"## Lab 10: Optimise a selection using \"neural network\" techniques\nWe optimise the rejection\\* efficiency metric by implementing a neural network on the variables that we identified as the most powerful one in the Lab 9.\n\nAs we learned in the Lab session 5, it is important to apply our selection to the \"test\" data set in order to check that we are not training our selections on a statistical fluctuation. For **each** question  of today's lab you should compare the value you achieve for the rejection\\* efficiency on the test data set **without** preparing a new selection.\n\n   * Start using only the 2 best variables identified last week and implement a neural network to classify signal and background events. This is very similar to what we did for the 2-dimensional classification exercise with the two variables used being variables from the neutrino data - **Done**\n   * Generalise your neural network to take a generic number of variables as input and optmise your selection\n   * For each of the optimised selections above, use the test data set to evaluate the rejection\\* efficiency\n   * How does the neural network method compare to the decision tree implemented last week?\n","pos":13,"state":"done","type":"cell"}
{"end":1557308722171,"exec_count":2,"id":"917380","input":"## Data Plot Prep\n\n# This cell contains the code to prepare the datasets\n# It uses sklearn.make_moons that generate sets of data sets to train and test classification algorithms\nimport sklearn\nimport sklearn.datasets\nimport sklearn.linear_model\n\n# Generate a dataset and plot it\n#     Npoints is the number of points in the dataset\n#     rndm is a random seed so different datasets can be generated\n#     noise is a parameter controlling how much points are scattered\ndef generate_data(Npoints,rndm=0,noise=0.20):\n    np.random.seed(rndm)\n    X, y = sklearn.datasets.make_moons(Npoints, noise=noise)\n    return X,y\n\n# Generate a dataset and plot it\n# X,y=generate_data(500)\n\n\n# Helper function to plot a decision boundary.\n# Input: pred_func. A function defined that operates on an array of points. \n#                   pred_func is expected to return an array of 0 and 1 \n#                   for each point passed in the input array a 0 or 1 is returned based on the condition\n#                   in the function\n#\n# # If you don't fully understand this function don't worry, it just generates the contour plot below.\ndef plot_decision_boundary(pred_func):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    # Predict the function value for the whole gid\n    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n\n\n# Helper function to calculate how often we get the prediction right\n# This is the accuracy of our classification e.g. N_right/N_tot\ndef accuracy(pred_func):\n    yhat=pred_func(X)\n    return 1.-np.count_nonzero(yhat-y)/len(y) \n\n\n\n# Because the one above doesn't allow the use of separate generated data (Data not called X, y) for Ex.5, and I'm not rewriting the whole code\ndef plot_decision_boundary1(pred_func, X, y):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    # Predict the function value for the whole gid\n    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n\n\ndef accuracy1(pred_func, X, y):\n    yhat=pred_func(X)\n    return 1.-np.count_nonzero(yhat-y)/len(y) ","kernel":"anaconda5","pos":3,"scrolled":true,"start":1557308718618,"state":"done","type":"cell"}
{"end":1557308722185,"exec_count":3,"id":"7b626d","input":"# # A simple way to separate the two categories\n# def predConst(x,C):\n#     return np.where(x[:,1]>C, 0, 1)\n\n# # Use lambda to turn the function into a function of just x\n# plot_decision_boundary(lambda x: predConst(x,0.5))\n# print(\"Accuracy\",accuracy(lambda x: predConst(x,0.5)) )","kernel":"anaconda5","pos":4,"scrolled":true,"start":1557308722179,"state":"done","type":"cell"}
{"end":1557308722195,"exec_count":4,"id":"51de36","input":"# These are parameter that are used in the training\n# \n#\n# num_examples = len(X) # training set size         all in buildmodel\n# nn_input_dim = 2 # input layer dimensionality\n# nn_output_dim = 2 # output layer dimensionality\n\n# # Gradient descent parameters (I picked these by hand)\n# epsilon = 0.01 # learning rate for gradient descent\n# reg_lambda = 0.01 # regularization strength     also in calculateloss","kernel":"anaconda5","pos":5.5,"start":1557308722191,"state":"done","type":"cell"}
{"end":1557308722267,"exec_count":6,"id":"3e20c4","input":"# Helper function to evaluate the total loss on the dataset\n# See notes from this morning lecture\n#\ndef calculate_loss(model, reg_lambda = 0.01):\n    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n    probs = calcProbsNN(model,X)   \n    # Calculating the loss\n    corect_logprobs = -np.log(probs[range(num_examples), y])\n    data_loss = np.sum(corect_logprobs)\n    # Add regulatization term to loss (optional)\n    data_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n    return 1./num_examples * data_loss","kernel":"anaconda5","pos":8,"start":1557308722261,"state":"done","type":"cell"}
{"end":1557308722290,"exec_count":7,"id":"8c1cd7","input":"# This function learns parameters for the neural network and returns the model.\n# - nn_hdim: Number of nodes in the hidden layer\n# - num_passes: Number of passes through the training data for gradient descent\n# - print_loss: If True, print the loss every 1000 iterations\n\ndef build_model(nn_hdim, num_passes=20000, print_loss=False, nn_input_dim = 2, nn_output_dim = 2, epsilon = 0.01, reg_lambda = 0.01):\n    # Some shit to try fixing things, this hopefully makes it take more than 2 inputs. It also removes the need for nn_input_dim & nn_output_dim\n    nn_input_dim = X.shape[1]\n    nn_output_dim = X.shape[1]\n    # Initialize the parameters to random values. We need to learn these.\n    np.random.seed(0)\n    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n    b1 = np.zeros((1, nn_hdim))\n    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n    b2 = np.zeros((1, nn_output_dim))\n#     W1 = np.ones(nn_input_dim, nn_hdim)\n#     W2 = np.ones(nn_hdim, nn_output_dim)\n\n    # This is what we return at the end\n    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n\n\n    # Gradient descent. For each batch...\n    for i in range(0, num_passes):\n\n        # Forward propagation\n        z1 = X.dot(W1) + b1\n        a1 = np.tanh(z1)\n        z2 = a1.dot(W2) + b2\n        exp_scores = np.exp(z2)\n        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n\n        # Backpropagation\n        delta3 = probs\n        delta3[range(num_examples), y] -= 1\n        dW2 = (a1.T).dot(delta3)\n        db2 = np.sum(delta3, axis=0, keepdims=True)\n        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n        dW1 = np.dot(X.T, delta2)\n        db1 = np.sum(delta2, axis=0)\n\n        # Add regularization terms (b1 and b2 don't have regularization terms)\n        dW2 += reg_lambda * W2\n        dW1 += reg_lambda * W1\n\n        # Gradient descent parameter update\n        W1 += -epsilon * dW1\n        b1 += -epsilon * db1\n        W2 += -epsilon * dW2\n        b2 += -epsilon * db2\n\n        # Assign new parameters to the model\n        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n\n        # Optionally print the loss.\n        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n        if print_loss and i % 1000 == 0:\n            print(\"Loss after iteration %i: %f\" %(i, calculate_loss(model)))\n\n    return model","kernel":"anaconda5","pos":9.5,"start":1557308722283,"state":"done","type":"cell"}
{"end":1557308722302,"exec_count":8,"id":"dd6a6b","input":"# # Build a model with a 3-dimensional hidden layer\n# model = build_model(3, print_loss=True,num_passes=500)\n\n# # Plot the decision boundary\n# plot_decision_boundary(lambda x: predict(model, x))\n# plt.title(\"Decision Boundary for hidden layer size 3\")\n# print(\"Accuracy\",accuracy(lambda x: predict(model,x)) )","kernel":"anaconda5","pos":11,"scrolled":false,"start":1557308722296,"state":"done","type":"cell"}
{"end":1557308722320,"exec_count":9,"id":"2263ec","input":"def DecBound (nlayer, passcnt):\n    \"\"\"Plots the prediction model for a NN of 'nlayer' hidden layers with 'passcnt' passes, and returns the accuracy\"\"\"\n    model = build_model(nlayer, print_loss=False,num_passes=passcnt)\n#     print(model)\n    plot_decision_boundary(lambda x: predict(model, x))\n    plt.title(\"Decision Boundary for hidden layer size {}\".format(nlayer) )\n    print(\"Accuracy\",accuracy(lambda x: predict(model,x)) )\n    plt.show()\n    return(accuracy1(lambda x: predict(model,x), X, y), model)\n\n#T This is the separate testing function, to save me rewriting everything so far\ndef DecBound1 (nlayer, passcnt, model, X, y):\n    \"\"\"Plots the prediction model for a NN of 'nlayer' hidden layers with 'passcnt' passes, and returns the accuracy. Similar to DecBound, but requires a premade model. ie for testing the model\"\"\"\n    plot_decision_boundary1(lambda x: predict(model, x), X, y)\n    plt.title(\"Decision Boundary for hidden layer size {}\".format(nlayer) )\n    print(\"Accuracy\",accuracy1(lambda x: predict(model,x), X, y))\n    plt.show()\n    return(accuracy1(lambda x: predict(model,x), X, y), model)\n\n# nlist = [1, 2, 3, 4, 5, 10, 50]\n# acclist = []\n# modellist = []\n# for i in nlist:\n#     A, B = DecBound(i, 500) # These don't need sensible names, as they are just to transfer directly to the list\n#     acclist.append(A)\n#     modellist.append(B)","kernel":"anaconda5","pos":12,"start":1557308722310,"state":"done","type":"cell"}
{"end":1557308722564,"exec_count":10,"id":"0357bd","input":"#Imports\nimport pandas as pd\nfrom pandas import DataFrame\nfrom matplotlib import pyplot as plt\n\nsignaldat = pd.read_csv('../data/signal_data.dat', sep = \" \")\nbackgrounddat = pd.read_csv('../data/background_data.dat', sep = \" \")\n\nsignaltr = pd.read_csv('../data/signal_training.dat', sep = \" \")\nbackgroundtr = pd.read_csv('../data/background_training.dat', sep = \" \")\n\n\nsigframedat = DataFrame(signaldat)\nbacframedat = DataFrame(backgrounddat)\nsigframetr = DataFrame(signaltr)\nbacframetr = DataFrame(backgroundtr)\n\nfulldatanames = list(signaldat.keys())\ndataname = list(signaldat.keys())[3:]","kernel":"anaconda5","pos":14,"start":1557308722329,"state":"done","type":"cell"}
{"end":1557308722584,"exec_count":11,"id":"e8c422","input":"# print(dataname)","kernel":"anaconda5","pos":14.75,"start":1557308722571,"state":"done","type":"cell"}
{"end":1557308722621,"exec_count":12,"id":"0a6d48","input":"#Part 1\n\n# effpullx-& effpully are the 2 best vars\n# We need to prepare the data sets, so they are in the form required by this NN\n# Training Data\n\n# Concatenating the training data into one big dataframe\ntraindata = pd.concat([sigframetr, bacframetr], axis = 0)\ntrainclassify = []\n\n# This will give us classifications of the rright length for all our training data (1 for signal, 0 for background)\nfor i in range(len(sigframetr['effpullx'])):\n    trainclassify.append(1)\nfor i in range(len(bacframetr['effpullx'])):\n    trainclassify.append(0)\n\n# Test Data\n# All the same stuff, but for test data instead of training. Could be worth making it into a big function.\ntestdata = pd.concat([sigframedat, bacframedat], axis = 0)\ntestclassify = []\n\nfor i in range(len(sigframedat['effpullx'])):\n    testclassify.append(1)\nfor i in range(len(bacframedat['effpullx'])):\n    testclassify.append(0)\n","kernel":"anaconda5","pos":15.5,"scrolled":true,"start":1557308722592,"state":"done","type":"cell"}
{"end":1557308852994,"exec_count":15,"id":"6bb8c8","input":"# This doesn't appear to work, but I'm not sure why.\nX, y = testdata[['effpullx', 'effpully']].values, testclassify\nnum_examples = len(X)\n# DecBound1(3, 500, model, X, y)\n# DecBound(3,5000)","kernel":"anaconda5","pos":19.5,"start":1557308852987,"state":"done","type":"cell"}
{"end":1557309727939,"exec_count":20,"id":"0f2837","input":"# Calculate the value of the output layers a2\ndef calcProbsNN(model,x):\n    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n#     print('x: ',x)\n#     print('length: ', len(x))\n    # Forward propagation\n    z1 = x.dot(W1) + b1\n    a1 = np.tanh(z1)\n    z2 = a1.dot(W2) + b2\n    # This is the softmax function\n    exp_scores = np.exp(z2)\n    # This is a2=yhat, eg the values of the output layer\n    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)    \n    return probs\n    \n# Helper function to predict an output (0 or 1)\ndef predict(model, x):\n    probs = calcProbsNN(model,x)   \n    return np.argmax(probs, axis=1)","kernel":"anaconda5","pos":7,"start":1557309727907,"state":"done","type":"cell"}
{"end":1557309827940,"exec_count":23,"id":"3df937","input":"# Part 3\n\ndef expval(nA, nAkeep, nBkeep):\n    \"\"\"returns value of Eps X Rho (Efficiency * Purity)\"\"\"\n    eff = nAkeep/nA\n    try:                                     # Yes, we're doing this again, again\n        pur = nAkeep / (nAkeep + nBkeep)\n    except ZeroDivisionError:\n        pur = 0\n    return(eff*pur)\n\n# We can say that the accuracy = (n - nBkept)/n = nAkept/n\n# So nAkept = acc * n, nBkept = n - (acc * n)\n#\nacc = accuracy1(lambda x: predict(model,x), X, y)\nn = num_examples # Just to save time typing\nnAkept = acc * n\nnBkept = n - (acc * n)\nnA = len(sigframedat['effpullx'])\n\nprint('eXr metric for test data: ',expval(nA, nAkept, nBkept))","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"eXr metric for test data:  0.5102040816326531\n"}},"pos":20.5,"start":1557309827933,"state":"done","type":"cell"}
{"end":1557310080890,"exec_count":24,"id":"db6cea","input":"# Part 4\n\n# I don't know, as I didn't get the decision tree last session, and the solution we were given doesn't work.\n# So I suppose it's better in that it actually gives a result","kernel":"anaconda5","pos":21.5,"start":1557310080812,"state":"done","type":"cell"}
{"end":1557310294078,"exec_count":25,"id":"6c86d9","input":"X, y = traindata[['effpullx', 'effpully']].values, trainclassify\n# Put this directly after wherever we set X\nnum_examples = len(X)\n\nmodel = build_model(3, print_loss=True,num_passes=500)\n\nDecBound(2, 5000)","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"Loss after iteration 0: 56.792070\n"},"1":{"name":"stdout","text":"Accuracy 0.76125\n"},"2":{"data":{"image/png":"9f9cea9fbc8aff50df140fbf937ede48f928526d","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":595},"needs_background":"light"}},"3":{"data":{"text/plain":"(0.76125, {'W1': array([[-356.55298473, -344.04458665],\n         [-367.35317922, -397.88216458]]),\n  'b1': array([[-523.68443343, -684.85993413]]),\n  'W2': array([[ 96.24503649, -95.86322097],\n         [-31.9012688 ,  32.24382163]]),\n  'b2': array([[-66.31264394,  66.31264394]])})"},"exec_count":25}},"pos":16.5,"scrolled":false,"start":1557310221899,"state":"done","type":"cell"}
{"id":"039773","input":"# Part 2\n\n# # Trying to generalise the number of variables\n# # Currently, 'x' changes dimensions after the 1st iteration. Need to work out why.\n\n# X, y = traindata[['effpullx', 'effpully', 'efftime']].values, trainclassify\n# # Put this directly after wherever we set X\n# num_examples = len(X)\n\n# model = build_model(3, print_loss=True,num_passes=500)\n\n# DecBound(2, 5000)","kernel":"anaconda5","pos":18.5,"scrolled":false,"state":"done","type":"cell"}
{"id":"cb9173","input":"","pos":22.5,"state":"done","type":"cell"}
{"id":0,"time":1559429089026,"type":"user"}
{"last_load":1556543789507,"type":"file"}
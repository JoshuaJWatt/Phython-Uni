{"backend_state":"running","kernel":"anaconda5","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":77385728},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1557152487974,"exec_count":1,"id":"f12393","input":"# Package imports\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport matplotlib\n# Display plots inline and change default figure size\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n","kernel":"anaconda5","pos":1,"start":1557152487967,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152488032,"exec_count":2,"id":"bc8f21","input":"# Helper function to plot a decision boundary.\n# Input: pred_func. A function defined that operates on an array of points. \n#                   pred_func is expected to return an array of 0 and 1 \n#                   for each point passed in the input array a 0 or 1 is returned based on the condition\n#                   in the function\n\n# If you don't fully understand this function don't worry, it just generates the contour plot below.\ndef plot_decision_boundary(pred_func):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    # Predict the function value for the whole gid\n    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n    \n    \n# Helper function to calculate how often we get the prediction right\n# This is the accuracy of our classification e.g. N_right/N_tot\ndef accuracy(pred_func):\n    yhat=pred_func(X)\n    return 1.-np.count_nonzero(yhat-y)/len(y) \n\n\n\n# Because the one above doesn't allow the use of separate generated data (Data not called X, y) for Ex.5, and I'm not rewriting the whole code\ndef plot_decision_boundary1(pred_func, X, y):\n    # Set min and max values and give it some padding\n    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n    h = 0.01\n    # Generate a grid of points with distance h between them\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    # Predict the function value for the whole gid\n    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the contour and training examples\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Spectral)\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Spectral)\n\n\ndef accuracy1(pred_func, X, y):\n    yhat=pred_func(X)\n    return 1.-np.count_nonzero(yhat-y)/len(y) ","kernel":"anaconda5","pos":3,"start":1557152487985,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152490067,"exec_count":3,"id":"d34ef6","input":"# This cell contains the code to prepare the datasets\n# It uses sklearn.make_moons that generate sets of data sets to train and test classification algorithms\nimport sklearn\nimport sklearn.datasets\nimport sklearn.linear_model\n\n# Generate a dataset and plot it\n#     Npoints is the number of points in the dataset\n#     rndm is a random seed so different datasets can be generated\n#     noise is a parameter controlling how much points are scattered\ndef generate_data(Npoints,rndm=0,noise=0.20):\n    np.random.seed(rndm)\n    X, y = sklearn.datasets.make_moons(Npoints, noise=noise)\n    return X,y","kernel":"anaconda5","pos":5,"start":1557152488060,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152491176,"exec_count":4,"id":"6d3094","input":"# Generate a dataset and plot it\nX,y=generate_data(500)\n\nprint('X:', X)\nprint('y: ', y)\n# Plot the data\nplt.scatter(X[:,0], X[:,1], s=40, c=y, cmap=plt.cm.Spectral) #1 is blue, 0 is red\n\n# Print the data (first 10 elements)\nprint(\"X=\",X[:10,:])\nprint(\"y=\",y[:10])","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"X: [[ 3.02402326e-01  8.96238169e-01]\n [-3.85982755e-01  4.87309788e-01]\n [ 1.90209311e-01  1.13254278e-01]\n [ 1.71457157e+00 -1.10330489e-01]\n [ 1.96706272e+00 -5.15800798e-01]\n [ 1.37332758e+00  2.66143527e-01]\n [ 1.96645759e-01 -3.17949126e-01]\n [ 2.09079968e+00  3.50945301e-01]\n [-8.27802027e-01  1.31965020e+00]\n [-3.73989147e-01  1.14007928e+00]\n [-1.13332039e+00  4.08038818e-01]\n [ 5.72687378e-02  6.21768767e-01]\n [ 9.85266188e-01 -2.38709756e-01]\n [ 2.56600567e-01  2.87929677e-01]\n [-6.79219220e-01  7.36576149e-01]\n [ 9.17732485e-01 -5.51702973e-01]\n [ 1.89729198e+00  3.46152370e-01]\n [ 7.75991166e-01 -3.53296646e-01]\n [-4.43552426e-01  1.00554191e+00]\n [ 6.31697234e-01  7.81677632e-01]\n [-8.73459010e-01  3.91027380e-01]\n [ 1.02623894e+00 -5.86398923e-01]\n [-1.26041164e+00 -1.56035824e-01]\n [ 3.45432043e-01  9.46494453e-01]\n [ 8.16368558e-01  7.53291667e-01]\n [ 1.49280504e+00 -3.42003043e-01]\n [ 8.88128691e-01  2.80734803e-01]\n [ 8.97080578e-01 -5.52903711e-01]\n [ 3.39555735e-01  9.14583683e-01]\n [-1.12361435e+00  3.79025286e-02]\n [ 1.67980124e+00 -4.58889448e-01]\n [-1.49553501e-01  9.34180659e-01]\n [-2.52250261e-02  1.45132480e+00]\n [-8.84928520e-01  8.56844605e-01]\n [ 1.14312929e+00 -7.37769093e-01]\n [ 2.15075311e+00  1.75020775e-01]\n [-2.50004645e-01 -7.46035879e-02]\n [ 1.47097790e+00  2.09246572e-02]\n [ 5.95250302e-01 -1.31523350e-01]\n [-7.76682900e-01  4.76629543e-02]\n [ 2.47434034e-01 -5.31343802e-01]\n [ 7.48072804e-01  4.92266093e-01]\n [ 1.27894231e+00 -4.04703967e-01]\n [-8.22541611e-01  4.15899982e-01]\n [ 4.21608593e-01  5.30990237e-01]\n [ 1.27282678e+00 -1.25273334e-01]\n [-1.02906832e+00  3.34511244e-01]\n [ 4.66672117e-02 -4.06830792e-01]\n [ 1.42576035e+00 -2.29062544e-01]\n [ 4.19772784e-01  9.60730446e-01]\n [ 1.04178459e+00 -4.21499375e-01]\n [-5.46187277e-01  8.71885442e-01]\n [ 5.74819004e-01 -5.01028506e-01]\n [-2.97100535e-01  7.44285115e-01]\n [-3.83967908e-02  7.96901551e-01]\n [ 1.15688684e+00  1.00932581e-01]\n [ 4.45834558e-01 -2.26963418e-01]\n [-4.45774485e-01  5.04423850e-01]\n [-9.92046613e-01  4.86252463e-01]\n [ 2.61726189e-01 -3.39645899e-01]\n [ 1.02488862e-01  6.28280204e-01]\n [ 6.10497471e-02 -1.53529090e-01]\n [ 9.59955362e-01 -7.81956460e-01]\n [ 1.92453429e+00 -2.70948765e-01]\n [ 3.13432633e-01 -1.44501122e-01]\n [-8.55319339e-01  2.96665703e-01]\n [ 9.33683850e-01 -2.64645308e-02]\n [ 2.10080286e+00  3.58688542e-01]\n [ 3.28211090e-01  4.08645903e-01]\n [ 4.64988091e-01  5.88056594e-01]\n [-6.56724287e-02  1.04698229e+00]\n [ 3.28444444e-01  8.02306633e-01]\n [ 7.41238831e-01 -3.94966510e-01]\n [ 1.94513439e+00  1.50345440e-01]\n [-8.84214241e-01  9.63853906e-01]\n [ 7.81119602e-01 -5.34282791e-01]\n [ 3.62103810e-01  4.61181569e-01]\n [ 3.78378349e-01  9.81016286e-01]\n [ 2.29890939e+00  7.43154454e-01]\n [ 3.42792152e-01  7.87020120e-02]\n [-2.26451836e-01 -6.50804432e-02]\n [-1.01046182e+00  1.94509298e-01]\n [ 2.14311328e+00 -3.46133344e-01]\n [-1.04308048e+00  4.23512702e-01]\n [ 3.74217333e-01 -6.29865602e-01]\n [ 5.99355319e-01 -2.63174150e-01]\n [ 1.35938079e+00 -2.69818132e-01]\n [-2.34335504e-01  9.18160523e-01]\n [ 8.31961311e-01 -4.28973020e-01]\n [ 6.97703009e-01  3.97926419e-01]\n [-9.50992468e-01  3.96637524e-01]\n [ 1.51520995e+00 -4.63431239e-01]\n [ 1.14822839e+00 -6.91311092e-01]\n [-9.71434308e-01  5.57511801e-01]\n [-8.45623707e-01  9.36809835e-01]\n [ 1.06108920e+00 -4.43683436e-01]\n [ 8.28391602e-01  1.05341688e+00]\n [ 1.64172616e+00 -6.17814068e-01]\n [ 7.66752491e-01  6.76630603e-01]\n [-9.72666169e-01  2.98760864e-01]\n [ 1.31167161e-01  1.01199141e+00]\n [ 4.32566463e-01  9.81648803e-02]\n [ 4.32797089e-01  6.22082959e-01]\n [ 1.49294187e+00  2.40080202e-01]\n [ 5.93854720e-01 -3.22621808e-02]\n [ 1.40054183e+00 -5.32091334e-01]\n [ 4.92359619e-01  1.18837125e+00]\n [-7.22751654e-01 -1.31992930e-02]\n [ 4.10810336e-01  1.96105284e-02]\n [-2.21105146e-01  1.13275620e+00]\n [-1.43476674e-01  1.41116587e-01]\n [ 1.16862171e+00 -4.42920722e-01]\n [ 1.45608107e-01  1.09821587e+00]\n [ 9.85769624e-01  1.44864938e-01]\n [ 1.69262255e+00 -8.73777889e-03]\n [ 1.88354267e+00  1.14155233e-02]\n [ 1.54555319e+00 -5.14765035e-01]\n [-4.11042017e-02 -1.87834051e-02]\n [-1.08497144e+00  4.56868617e-01]\n [-6.41623711e-01  6.89019037e-01]\n [ 1.86366640e+00 -3.11534253e-01]\n [ 7.45418346e-01  4.63335966e-01]\n [-4.46100079e-01  6.79271846e-01]\n [ 6.44595240e-01 -2.32539776e-01]\n [ 1.64592225e+00 -1.09333042e-01]\n [-1.25849365e+00 -2.67891026e-01]\n [ 6.03487734e-01  7.12689602e-01]\n [ 1.48678835e+00 -2.12464172e-01]\n [ 1.26353335e+00 -1.29875385e-01]\n [ 1.39988801e+00 -5.78439773e-01]\n [ 1.64819678e+00  1.46487076e-01]\n [-9.19908061e-01  7.19233454e-02]\n [ 3.58075819e-01  2.23621348e-01]\n [ 2.94823595e-01  8.12370709e-01]\n [-3.04329066e-01  6.40005747e-02]\n [ 2.23853406e+00  3.99663544e-01]\n [ 1.61322453e+00 -1.11613077e-01]\n [ 1.81052489e+00 -4.19022226e-02]\n [ 1.79567796e+00 -7.03137483e-02]\n [-6.57688125e-01  4.72051382e-01]\n [-8.17144942e-01  9.43212483e-01]\n [ 7.15463189e-01  5.21244654e-01]\n [ 8.10546762e-01  2.91957383e-01]\n [ 1.18295208e+00  1.95805318e-01]\n [ 2.02317049e+00  3.80924156e-01]\n [ 1.18722042e+00 -3.07301765e-03]\n [ 2.10401374e-01  3.06896545e-03]\n [ 5.47372737e-03 -3.49067367e-01]\n [-1.26831188e+00 -1.01868746e-01]\n [ 1.40026219e+00  5.41232711e-02]\n [-1.67663473e-01  6.22096570e-01]\n [ 9.61228740e-01 -4.54943486e-01]\n [-6.11381030e-02  1.11461509e+00]\n [ 1.99886163e+00  5.29772096e-01]\n [ 1.22293247e-01  6.33554507e-01]\n [ 9.69125170e-01  4.27600370e-01]\n [ 7.71969434e-01  6.83728431e-01]\n [ 8.07206352e-01  2.60050120e-02]\n [ 1.06827433e+00 -2.68910297e-01]\n [ 5.94079607e-01  4.37403063e-02]\n [-1.66206402e-01  3.11022414e-01]\n [-1.06536599e+00  2.04070379e-01]\n [ 6.47933244e-01  8.11624352e-01]\n [ 1.00343975e+00 -1.10586772e+00]\n [-8.65660362e-01  3.12964532e-01]\n [ 4.77783304e-01  6.36326879e-01]\n [ 1.39850767e+00 -3.68777948e-01]\n [ 1.13601150e-01 -1.53358167e-01]\n [ 1.81396870e+00  4.64282182e-01]\n [ 1.62816004e+00  2.37494674e-01]\n [ 1.66095250e+00  2.05576087e-02]\n [-7.14264191e-01  7.83347990e-01]\n [ 1.94300677e+00 -9.40044473e-02]\n [ 8.90939933e-01 -5.67067288e-01]\n [ 1.65081252e+00  2.01509972e-01]\n [-7.35384238e-01  6.95410433e-01]\n [ 3.29221242e-01 -1.83738730e-01]\n [ 8.44794135e-01  6.65890698e-01]\n [ 4.96586024e-01 -4.50607848e-01]\n [ 1.96456482e+00 -1.35245984e-01]\n [ 4.44261796e-01 -4.20098170e-01]\n [-5.53019562e-01  6.33125963e-01]\n [ 2.67965696e-01  1.30707159e+00]\n [ 1.96309614e+00  2.74567051e-01]\n [ 5.62924327e-01  6.90271203e-01]\n [ 7.17846949e-01 -5.00916925e-01]\n [ 1.52423764e+00 -2.07875413e-01]\n [ 1.54329150e+00 -1.36251986e-01]\n [ 5.29366345e-01 -7.70558785e-04]\n [ 4.14995206e-01  1.17487897e+00]\n [ 4.97548354e-01 -4.04115433e-01]\n [ 1.57132077e+00 -1.40582388e-01]\n [ 5.92837396e-01  9.07601202e-01]\n [ 5.77124768e-02  2.41186401e-01]\n [ 1.93271328e+00 -4.47640542e-01]\n [ 3.19443660e-01 -6.41843373e-02]\n [ 1.30089276e+00 -3.76794969e-01]\n [ 3.85197525e-01  6.53422820e-01]\n [ 9.00181940e-01  3.60327814e-02]\n [-9.86573605e-01  3.47352432e-01]\n [-1.65273212e-01  9.86316618e-01]\n [-4.99824610e-01  7.82131813e-01]\n [-3.20892288e-01  1.16452894e+00]\n [ 1.56748851e+00  3.25707907e-01]\n [-6.20028811e-01  4.82731055e-01]\n [-3.87151469e-01  2.54400945e-01]\n [-9.27502601e-01  3.16043153e-01]\n [ 1.37626812e+00 -1.22326575e-01]\n [ 9.57469224e-01  8.18975768e-01]\n [ 1.46220469e-01  4.73580260e-02]\n [ 1.51795384e-01  6.35640006e-01]\n [-3.25609596e-01  4.14027913e-01]\n [ 7.15528810e-01  6.34190534e-01]\n [ 1.66571891e+00  2.36390619e-01]\n [ 1.06579700e+00  2.15080293e-01]\n [ 1.10971222e+00 -7.67532789e-01]\n [ 8.70545315e-01  4.30995421e-01]\n [-3.37197408e-01  8.04506245e-01]\n [-9.60406542e-01  2.16387044e-01]\n [-2.75567069e-01  9.46069305e-02]\n [ 7.71484221e-01  5.88459506e-01]\n [ 1.79053947e-01  1.41766846e+00]\n [-8.12392503e-01  1.82119628e-02]\n [ 5.20963086e-01  1.00573291e+00]\n [ 1.23440207e+00 -2.90873468e-01]\n [ 1.33842217e-01 -2.44830731e-01]\n [-3.39444486e-01  7.75968394e-01]\n [-1.15991203e+00 -5.50260616e-02]\n [ 3.11395789e-01  8.83746831e-01]\n [-5.99065679e-01  7.51075656e-01]\n [ 1.52581909e+00 -4.49362679e-01]\n [-2.63621937e-01  8.20952500e-01]\n [-1.76942588e-01  6.10323762e-01]\n [ 3.19592317e-01  1.10504133e+00]\n [ 7.17002959e-01 -6.46470648e-01]\n [ 1.58981964e+00 -4.32921722e-01]\n [ 5.79841482e-01 -3.41923619e-01]\n [-3.17833760e-02  7.32581912e-01]\n [-7.56367696e-01  4.79925422e-01]\n [ 4.24430810e-01 -6.68449005e-01]\n [-3.02996239e-01  7.29902508e-01]\n [-1.72064566e-01  1.11097832e+00]\n [ 7.75879478e-02  2.62780850e-01]\n [-3.64532979e-01  5.35489783e-01]\n [ 1.55319161e+00 -7.49421652e-01]\n [ 1.32093691e+00 -1.33646670e-01]\n [ 7.41257429e-01 -3.02456202e-01]\n [-8.42971783e-01  7.13443346e-02]\n [-9.90843252e-02  6.80856023e-01]\n [ 8.24308287e-01  4.57567735e-01]\n [ 2.10281041e+00  2.18790752e-01]\n [-3.11679192e-01  6.69564498e-01]\n [ 8.89054153e-01  4.19792489e-01]\n [ 1.21974445e+00  4.84229690e-01]\n [ 2.40240069e-01  9.44679990e-01]\n [ 2.94167450e-01  9.16915971e-01]\n [ 6.45159154e-01  3.37601983e-01]\n [-8.19248532e-01  5.26316207e-01]\n [-3.00807401e-01  2.61417229e-01]\n [-6.26610723e-01  4.85486652e-01]\n [ 7.27386464e-01  5.27925346e-01]\n [ 9.99453237e-01  4.57066791e-01]\n [ 3.21176058e-01 -3.54348165e-02]\n [ 6.61850169e-01  3.49498774e-01]\n [ 6.78920894e-01 -4.95546157e-01]\n [ 1.03952488e+00 -2.13229648e-01]\n [ 1.58881630e+00 -3.28996599e-01]\n [-9.04681315e-01  1.77439475e-01]\n [ 8.57603494e-01  1.68111252e-01]\n [ 1.58644776e+00 -2.95443160e-01]\n [ 1.05784303e+00 -5.75836709e-01]\n [-1.98866774e-01  1.00309942e+00]\n [ 1.73430850e+00 -2.77998715e-01]\n [ 2.98691374e-01 -4.54023925e-01]\n [-2.76002918e-01  1.11454039e+00]\n [-6.90634117e-01  3.18461287e-01]\n [ 3.49448077e-01  1.31391319e+00]\n [ 5.62244107e-01 -1.16219577e-01]\n [ 4.77601815e-01 -4.31452787e-01]\n [ 7.05600272e-01 -4.54066435e-01]\n [-1.07692922e+00  2.97699991e-01]\n [ 9.98545584e-01 -4.25845256e-01]\n [-6.60885429e-01  1.13194018e+00]\n [-6.29875762e-01  3.25408226e-01]\n [-7.78134947e-01  7.37166502e-01]\n [-9.76024755e-01  1.74196547e-01]\n [ 1.67550406e-02  5.60147648e-01]\n [ 4.93821700e-01  6.83054977e-01]\n [ 1.04859069e+00  3.60487325e-01]\n [-8.66652342e-01  3.30469906e-01]\n [-7.52169205e-01  7.48959719e-01]\n [ 2.45378256e-02  9.59753349e-01]\n [ 3.20652992e-01  8.77702811e-01]\n [-6.49938069e-01  8.72587153e-01]\n [ 9.94327090e-01 -5.90438297e-01]\n [ 1.17396146e+00 -7.40565153e-01]\n [ 6.68803762e-01  3.96172019e-01]\n [-2.83097121e-01  1.20587730e-01]\n [ 6.73940902e-01 -4.70642680e-01]\n [ 7.73887661e-01  8.74200692e-01]\n [ 3.03828269e-01 -1.93875221e-01]\n [ 3.63326421e-01 -4.34558004e-01]\n [ 9.63623965e-01  2.25034719e-01]\n [-1.67154600e-01  2.23079088e-01]\n [ 1.63794034e+00 -5.33026826e-01]\n [ 1.94974329e+00  2.61319575e-01]\n [-8.25228556e-01  4.96200275e-02]\n [-4.88904546e-01  7.24039948e-01]\n [ 5.10190855e-01  5.07179549e-01]\n [ 2.26497398e+00  2.81847717e-01]\n [ 1.95865530e+00  1.35309322e-01]\n [ 2.95024749e-02  8.05756312e-01]\n [-1.16933640e-01  8.47475807e-01]\n [-2.85809360e-01  7.80110368e-01]\n [ 8.50257185e-01  2.94950556e-01]\n [ 7.53010092e-01 -4.36422800e-01]\n [-9.00671134e-02  1.38053003e+00]\n [ 5.48608784e-01 -7.68293748e-01]\n [ 3.36959540e-01  9.02505881e-01]\n [-1.28090712e+00  1.41363438e-02]\n [ 8.14576566e-02  4.12228400e-01]\n [ 1.36206772e+00  1.80603411e-02]\n [ 2.32198260e-01 -4.85126189e-01]\n [ 2.19086547e+00  7.15366638e-01]\n [ 1.15270905e+00 -7.28959456e-01]\n [-7.93832755e-01 -3.96848219e-01]\n [ 8.99260751e-01 -2.96003142e-01]\n [ 9.60334003e-01  1.84643096e-01]\n [ 5.16961613e-01 -3.63336458e-01]\n [-9.59946753e-02  2.06877877e-01]\n [ 2.93598298e-01  3.03635947e-01]\n [-9.49163504e-01  7.54056635e-01]\n [ 1.42270357e+00 -4.30280598e-01]\n [ 1.07218000e+00  3.32105868e-01]\n [ 1.36269873e+00 -5.50739679e-01]\n [ 5.53578721e-02  7.24363409e-01]\n [ 8.38670610e-03 -3.75899100e-02]\n [-9.99759554e-02  3.97566237e-01]\n [ 4.05607105e-01  7.19409592e-01]\n [-6.08982377e-01  9.90775328e-01]\n [ 1.68094190e+00  2.40635032e-01]\n [ 1.94679043e+00  2.77723399e-01]\n [ 1.04454257e-01  4.76793197e-01]\n [ 2.51621589e-01 -5.03089610e-02]\n [ 1.51088642e+00 -1.64877421e-01]\n [-3.83216838e-01  6.66112512e-01]\n [ 1.89818100e+00 -6.07823150e-02]\n [ 7.05117489e-01  6.85533631e-01]\n [ 7.16969904e-01 -4.14584967e-01]\n [-6.80206340e-02  5.86855101e-01]\n [ 1.04973141e+00  3.04337347e-01]\n [ 8.56634951e-01 -5.13986149e-01]\n [ 4.69316594e-01  1.19817778e+00]\n [ 1.58392333e-01  4.58833295e-01]\n [ 7.67024386e-01  6.32525634e-01]\n [ 2.01652084e+00  5.40398497e-01]\n [ 1.14680050e+00  6.06839305e-01]\n [ 7.87901734e-01  3.21717838e-01]\n [ 2.95244427e-03  1.73927513e-01]\n [ 8.79432102e-01  5.60911463e-01]\n [-9.47652238e-01  6.96438714e-01]\n [ 1.09250531e+00 -3.73354677e-01]\n [ 1.35188326e+00 -2.56485818e-01]\n [ 1.77705231e+00 -4.26645054e-01]\n [ 1.07130709e-01  1.03557950e+00]\n [-1.10242063e+00  3.82261673e-01]\n [ 7.67157724e-01  7.87447069e-01]\n [ 9.91857086e-01 -4.80664129e-01]\n [-2.98859120e-01  9.25970484e-01]\n [-5.98141087e-01  8.83367682e-01]\n [ 8.73727343e-01  3.07074479e-01]\n [ 9.02018920e-01  5.56595226e-01]\n [ 1.85214318e+00 -5.31807986e-01]\n [ 9.90135186e-01  4.78067202e-02]\n [-1.02222208e+00  9.04059377e-01]\n [ 9.50394302e-01 -1.83958161e-01]\n [ 1.44689642e+00 -4.77684716e-01]\n [ 3.73002094e-01  6.08887382e-01]\n [ 7.26785451e-01 -4.29246151e-01]\n [ 4.26384251e-01  1.03977462e-02]\n [ 1.90506512e+00  1.29676372e-01]\n [-2.82436921e-01  6.22283428e-01]\n [ 7.21558158e-01 -7.14564511e-01]\n [ 2.26325018e-01  3.20591213e-01]\n [ 2.24645443e-01  9.54406402e-01]\n [ 1.86800467e+00 -5.15557041e-02]\n [ 5.14460913e-01  1.14459383e+00]\n [ 1.94942300e+00 -5.36881117e-03]\n [-4.51888451e-01  4.91306779e-01]\n [ 9.78247192e-01  8.25088935e-01]\n [ 3.52890309e-01  8.34322162e-02]\n [ 1.10882651e+00  6.52941837e-01]\n [ 6.76917694e-01 -5.31844254e-01]\n [ 9.87693823e-01 -6.70653175e-01]\n [-1.00684209e+00  3.26738385e-01]\n [ 3.49889076e-02  3.52039701e-01]\n [-3.27529070e-01  3.11919816e-01]\n [-5.61853223e-01  1.20936288e+00]\n [-2.91454631e-01  8.40761266e-01]\n [ 5.52935904e-01 -6.20389647e-01]\n [-5.99904398e-01  7.47015988e-01]\n [ 7.88377726e-01 -3.96599734e-01]\n [-6.84190998e-02  9.99906726e-01]\n [ 1.94986551e+00  1.33028629e-01]\n [ 1.79362392e+00  2.01385245e-01]\n [-8.88196026e-04  6.26286049e-02]\n [ 4.22598993e-01 -1.16044941e-01]\n [-7.14834996e-01  3.38703111e-01]\n [ 3.16981502e-01  9.37924986e-01]\n [-3.61149785e-02  9.35694094e-01]\n [ 2.09646717e+00  8.96971872e-02]\n [ 1.60190519e+00 -3.91226770e-01]\n [ 1.67273717e+00 -1.43855206e-01]\n [ 1.97860130e+00 -2.73788284e-02]\n [ 9.43741048e-01 -5.39045712e-01]\n [ 8.24300763e-02  7.65336837e-01]\n [ 9.40801324e-01  8.41599454e-01]\n [ 1.69245912e-01  2.74056851e-01]\n [ 1.38970778e-01  1.13024492e+00]\n [ 5.72399268e-01 -4.84596392e-01]\n [ 4.46610679e-01 -1.53626946e-01]\n [ 6.39071532e-01  5.97214490e-01]\n [ 4.28906849e-01 -1.75722859e-01]\n [ 2.57379819e-01  5.11696550e-01]\n [ 1.00651350e+00 -2.47987497e-01]\n [ 1.92545519e+00 -4.19096444e-01]\n [ 1.36812763e+00  8.59437543e-01]\n [ 2.09910983e-01  1.04546940e+00]\n [ 1.43437668e+00 -5.19969497e-01]\n [ 2.06566895e+00  3.28056406e-01]\n [-1.61155489e-01  9.34019558e-02]\n [ 1.95302266e+00 -4.73973530e-02]\n [ 1.07201276e+00  4.34768644e-01]\n [ 1.12412434e+00 -8.83040235e-01]\n [ 5.55432904e-01  6.29373760e-01]\n [ 1.70796230e+00 -2.33464135e-01]\n [ 1.68368523e+00 -2.59227218e-01]\n [-7.08656017e-04  1.01466739e+00]\n [ 4.05576721e-01  4.57664677e-02]\n [ 6.41996718e-01  9.14574632e-02]\n [-3.69120657e-01  5.05526359e-01]\n [ 1.09615422e+00 -5.52063236e-01]\n [-5.00821856e-01  8.57499299e-01]\n [-8.38746581e-02  9.06056689e-01]\n [-1.00467471e+00 -2.43118343e-01]\n [-7.87934572e-01  6.65052694e-01]\n [ 9.72311031e-01  6.60805154e-01]\n [ 9.30632868e-01  4.52654780e-01]\n [ 2.98163937e-01  6.89499751e-01]\n [-7.82488228e-01  1.00777745e+00]\n [ 2.12103214e+00  2.77897083e-01]\n [ 1.97406137e+00 -2.44115842e-02]\n [ 4.39066033e-01  1.14269587e-01]\n [ 1.62241080e+00 -2.86756797e-01]\n [ 1.33074340e+00 -6.87769671e-01]\n [ 2.01054287e+00 -4.23871830e-02]\n [ 8.43016653e-02  9.44846174e-01]\n [ 1.80110094e-01  1.21943563e-01]\n [ 1.78945749e+00  2.93997226e-01]\n [-2.33985716e-01  7.85572878e-01]\n [ 2.56111910e-01  8.77684251e-01]\n [ 1.77118477e-01 -4.31386558e-01]\n [ 1.85022505e+00  1.10985484e-01]\n [ 1.84600302e+00 -3.39800009e-01]\n [ 4.66645263e-01 -1.53584141e-01]\n [-8.27085053e-01  5.08005965e-01]\n [-7.18632355e-01  2.83145879e-01]\n [ 1.90783192e+00 -4.61323640e-02]\n [-2.82802890e-01  1.11076611e+00]\n [ 1.18438868e+00 -8.24077131e-01]\n [ 3.34818986e-01  4.41468696e-01]\n [ 3.87196805e-01  5.45648045e-01]\n [ 6.74192356e-01 -5.41619527e-01]\n [ 1.20989585e+00  4.33508543e-01]\n [-3.81714688e-01  9.53203818e-01]\n [ 5.82614236e-01 -2.14043501e-01]\n [ 1.88887740e+00  3.16689268e-01]\n [-4.34329561e-01  9.23833935e-01]\n [ 1.74758167e+00  2.36633596e-01]\n [ 9.31923767e-01  3.90836627e-01]\n [-4.05679065e-01  5.70577529e-01]\n [ 2.76233153e-01 -6.86596662e-02]\n [ 1.33405407e+00 -4.92488401e-01]\n [ 2.93110438e-01  9.56126741e-01]\n [ 2.15035544e+00  2.61714873e-01]\n [ 4.79061310e-01  1.12011526e+00]\n [ 1.66360360e-01  5.73608612e-01]\n [ 3.29257462e-01  3.97148299e-02]\n [-1.10600222e+00 -1.31511049e-01]\n [ 5.21623813e-01  1.89314003e-01]\n [-7.80413218e-01  5.24859266e-01]\n [ 1.08052154e+00  2.21326570e-01]\n [ 9.52167941e-01 -5.55983295e-01]\n [-8.35077202e-01  2.81605960e-01]\n [-1.55981290e-01  5.41606056e-01]\n [ 6.04003650e-01 -1.76416786e-01]\n [-8.20497971e-01  4.06118163e-01]\n [-4.60986697e-01  1.22587307e+00]\n [ 7.11426877e-01  4.69151192e-01]\n [-5.37749644e-01  5.44618764e-01]]\ny:  [0 1 1 1 1 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 1 1 1\n 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1\n 0 1 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1\n 0 0 0 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1\n 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 1 0\n 1 1 1 1 0 1 1 0 1 1 1 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 0 0\n 0 0 1 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1\n 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1\n 0 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1\n 0 1 0 1 1 0 0 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0\n 0 0 1 0 0 1 1 0 1 1 1 0 1 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 1 1 1 1\n 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 0 0 1 0 0\n 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 1 0 1 0 0\n 1 1 0 1 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0]\nX= [[ 0.30240233  0.89623817]\n [-0.38598275  0.48730979]\n [ 0.19020931  0.11325428]\n [ 1.71457157 -0.11033049]\n [ 1.96706272 -0.5158008 ]\n [ 1.37332758  0.26614353]\n [ 0.19664576 -0.31794913]\n [ 2.09079968  0.3509453 ]\n [-0.82780203  1.3196502 ]\n [-0.37398915  1.14007928]]\ny= [0 1 1 1 1 0 1 1 0 0]\n"},"1":{"data":{"image/png":"189811f62ecb172c7c42d82db023b5c6c4b6de16","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":467,"width":605},"needs_background":"light"}}},"pos":6,"scrolled":true,"start":1557152490076,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152492196,"exec_count":5,"id":"89ec8f","input":"# Here we show how a boundary can be defined and plotted\n\n# First a simple function of X to illustrate the mechanism. \n# In this example we define a prediction that all points above 0 on the vertical axis belong to category 0\ndef simplePred(x):\n    return np.where(x[:,1]>0., 0, 1)\n\nplot_decision_boundary(simplePred)\n\n# Calculate the accuracy of this predition\nprint(\"Accuracy=\",accuracy(simplePred))\n","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"Accuracy= 0.796\n"},"1":{"data":{"image/png":"0ab46c448e747daaac7d6db827c10f1b2016d61f","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":467,"width":605},"needs_background":"light"}}},"pos":8,"start":1557152491184,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152493080,"exec_count":6,"id":"e7d158","input":"# The example above is impractical, as if we want to use a different classification \n# (eg points above 0.5 are assigned to category 0) we need to write a new function.\n\n# A simple way to separate the two categories\ndef predConst(x,C):\n    return np.where(x[:,1]>C, 0, 1)\n\n# Use lambda to turn the function into a function of just x\nplot_decision_boundary(lambda x: predConst(x,0.5))\nprint(\"Accuracy\",accuracy(lambda x: predConst(x,0.5)) )\n","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"Accuracy 0.786\n"},"1":{"data":{"image/png":"1469a2fd5ea5a013407d1461d3a2e87f94d41614","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":467,"width":605},"needs_background":"light"}}},"pos":9,"start":1557152492204,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152493095,"exec_count":7,"id":"c5fcf3","input":"# Your code goes here:\n\nmax_ = 0\nfor i in np.arange (-1, 1, 0.01):\n    accval = accuracy(lambda x: predConst(x,i))\n    if accval > max_:\n        max_ = accval\n        maxC = i\n\n\nprint(\"max acuuracy: \", max_)\nprint(\"produced by C val: \", maxC)","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"max acuuracy:  0.848\nproduced by C val:  0.28000000000000114\n"}},"pos":11,"start":1557152493090,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152493598,"exec_count":8,"id":"c7a65d","input":"# Function to define a linear model\ndef predLinear(x,a,b):\n    return np.where(x[:,1]> (a * x[:,0] + b), 0, 1)\n\nmax_ = 0\nfor a in np.arange (-1, 1, 0.01):\n    for b in np.arange (-1, 1, 0.01):\n        accval = accuracy(lambda x: predLinear(x,a,b))\n        if accval > max_:\n            max_ = accval\n            maxa, maxb = a, b\n\nprint(\"max accuracy: \", max_)\nprint(\"Produced by a val: \", maxa)\nprint(\"and b val: \", maxb)","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"max accuracy:  0.876\nProduced by a val:  0.27000000000000113\nand b val:  0.010000000000000897\n"}},"pos":13,"start":1557152493102,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152493609,"exec_count":9,"id":"75edb9","input":"# These are parameter that are used in the training\n# \nnum_examples = len(X) # training set size\nnn_input_dim = 2 # input layer dimensionality\nnn_output_dim = 2 # output layer dimensionality\n\n# Gradient descent parameters (I picked these by hand)\nepsilon = 0.01 # learning rate for gradient descent\nreg_lambda = 0.01 # regularization strength","kernel":"anaconda5","pos":15,"start":1557152493604,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152493622,"exec_count":10,"id":"d366f1","input":"# Calculate the value of the output layers a2\ndef calcProbsNN(model,x):\n    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n    # Forward propagation\n    z1 = x.dot(W1) + b1\n    a1 = np.tanh(z1)\n    z2 = a1.dot(W2) + b2\n    # This is the softmax function\n    exp_scores = np.exp(z2)\n    # This is a2=yhat, eg the values of the output layer\n    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)    \n    return probs\n    \n# Helper function to predict an output (0 or 1)\ndef predict(model, x):\n    probs = calcProbsNN(model,x)   \n    return np.argmax(probs, axis=1)","kernel":"anaconda5","pos":16,"start":1557152493616,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152493660,"exec_count":11,"id":"f1f641","input":"# Helper function to evaluate the total loss on the dataset\n# See notes from this morning lecture\n#\ndef calculate_loss(model):\n    W1, b1, W2, b2 = model['W1'], model['b1'], model['W2'], model['b2']\n    probs = calcProbsNN(model,X)   \n    # Calculating the loss\n    corect_logprobs = -np.log(probs[range(num_examples), y])\n    data_loss = np.sum(corect_logprobs)\n    # Add regulatization term to loss (optional)\n    data_loss += reg_lambda/2 * (np.sum(np.square(W1)) + np.sum(np.square(W2)))\n    return 1./num_examples * data_loss","kernel":"anaconda5","pos":17,"start":1557152493628,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152493678,"exec_count":12,"id":"9889c6","input":"# This function learns parameters for the neural network and returns the model.\n# - nn_hdim: Number of nodes in the hidden layer\n# - num_passes: Number of passes through the training data for gradient descent\n# - print_loss: If True, print the loss every 1000 iterations\ndef build_model(nn_hdim, num_passes=20000, print_loss=False):\n    \n    # Initialize the parameters to random values. We need to learn these.\n    np.random.seed(0)\n    W1 = np.random.randn(nn_input_dim, nn_hdim) / np.sqrt(nn_input_dim)\n    b1 = np.zeros((1, nn_hdim))\n    W2 = np.random.randn(nn_hdim, nn_output_dim) / np.sqrt(nn_hdim)\n    b2 = np.zeros((1, nn_output_dim))\n\n    # This is what we return at the end\n    model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n\n\n    # Gradient descent. For each batch...\n    for i in range(0, num_passes):\n\n        # Forward propagation\n        z1 = X.dot(W1) + b1\n        a1 = np.tanh(z1)\n        z2 = a1.dot(W2) + b2\n        exp_scores = np.exp(z2)\n        probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n\n        # Backpropagation\n        delta3 = probs\n        delta3[range(num_examples), y] -= 1\n        dW2 = (a1.T).dot(delta3)\n        db2 = np.sum(delta3, axis=0, keepdims=True)\n        delta2 = delta3.dot(W2.T) * (1 - np.power(a1, 2))\n        dW1 = np.dot(X.T, delta2)\n        db1 = np.sum(delta2, axis=0)\n\n        # Add regularization terms (b1 and b2 don't have regularization terms)\n        dW2 += reg_lambda * W2\n        dW1 += reg_lambda * W1\n\n        # Gradient descent parameter update\n        W1 += -epsilon * dW1\n        b1 += -epsilon * db1\n        W2 += -epsilon * dW2\n        b2 += -epsilon * db2\n        \n        # Assign new parameters to the model\n        model = { 'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n        \n        # Optionally print the loss.\n        # This is expensive because it uses the whole dataset, so we don't want to do it too often.\n        if print_loss and i % 1000 == 0:\n            print(\"Loss after iteration %i: %f\" %(i, calculate_loss(model)))\n    \n    return model","kernel":"anaconda5","pos":19,"start":1557152493671,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152495114,"exec_count":13,"id":"3e4e20","input":"# Build a model with a 3-dimensional hidden layer\nmodel = build_model(3, print_loss=True,num_passes=500)\n\n# Plot the decision boundary\nplot_decision_boundary(lambda x: predict(model, x))\nplt.title(\"Decision Boundary for hidden layer size 3\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model,x)) )\n","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"Loss after iteration 0: 0.358460\n"},"1":{"name":"stdout","text":"Accuracy 0.964\n"},"2":{"data":{"image/png":"df3dac9e4ea7189f2178710bf14b797ef6416a44","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}}},"pos":21,"scrolled":true,"start":1557152493683,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152506259,"exec_count":14,"id":"bb1099","input":"# Ex 3\ndef GeneralListPlot(XList, YList, xlabel, ylabel):\n    \"\"\"A general function to plot 2 lists of floats, and label their axes\"\"\"\n    plt.plot(XList, YList)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show()\n    return()\n# Without a function: (Because at this point I have no idea which is preffered)\n\"\"\"\nmodel1 = build_model(1, print_loss=True,num_passes=500)\nmodel2 = build_model(2, print_loss=True,num_passes=500)\nmodel3 = build_model(3, print_loss=True,num_passes=500)\nmodel4 = build_model(4, print_loss=True,num_passes=500)\nmodel5 = build_model(5, print_loss=True,num_passes=500)\nmodel10 = build_model(10, print_loss=True,num_passes=500)\nmodel50 = build_model(50, print_loss=True,num_passes=500)\n\nplot_decision_boundary(lambda x: predict(model1, x))\nplt.title(\"Decision Boundary for hidden layer size 1\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model1,x)) )\nplt.show()\n\nplot_decision_boundary(lambda x: predict(model2, x))\nplt.title(\"Decision Boundary for hidden layer size 2\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model2,x)) )\nplt.show()\n\nplot_decision_boundary(lambda x: predict(model3, x))\nplt.title(\"Decision Boundary for hidden layer size 3\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model3,x)) )\nplt.show()\n\nplot_decision_boundary(lambda x: predict(model4, x))\nplt.title(\"Decision Boundary for hidden layer size 4\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model4,x)) )\nplt.show()\n\nplot_decision_boundary(lambda x: predict(model5, x))\nplt.title(\"Decision Boundary for hidden layer size 5\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model5,x)) )\nplt.show()\n\nplot_decision_boundary(lambda x: predict(model10, x))\nplt.title(\"Decision Boundary for hidden layer size 10\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model10,x)) )\nplt.show()\n\nplot_decision_boundary(lambda x: predict(model50, x))\nplt.title(\"Decision Boundary for hidden layer size 50\")\nprint(\"Accuracy\",accuracy(lambda x: predict(model50,x)) )\nplt.show()\n\"\"\"\n\n# With a loop/Function\ndef DecBound (nlayer, passcnt):\n    \"\"\"Plots the prediction model for a NN of 'nlayer' hidden layers with 'passcnt' passes, and returns the accuracy\"\"\"\n    model = build_model(nlayer, print_loss=False,num_passes=passcnt)\n    plot_decision_boundary(lambda x: predict(model, x))\n    plt.title(\"Decision Boundary for hidden layer size {}\".format(nlayer) )\n    print(\"Accuracy\",accuracy(lambda x: predict(model,x)) )\n    plt.show()\n    return(accuracy1(lambda x: predict(model,x), X, y), model)\n\nnlist = [1, 2, 3, 4, 5, 10, 50]\nacclist = []\nmodellist = []\nfor i in nlist:\n    A, B = DecBound(i, 500) # These don't need sensible names, as they are just to transfer directly to the list\n    acclist.append(A)\n    modellist.append(B)\n\n# I don't know how to make a table, so...\nGeneralListPlot(nlist, acclist, \"Number of Hidden Layers\", \"Accuracy\")","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"Accuracy 0.858\n"},"1":{"data":{"image/png":"da3e67349c2ad8af17834d464d0459c0769a631a","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}},"10":{"name":"stdout","text":"Accuracy 0.976\n"},"11":{"data":{"image/png":"feb439bc6f9bdc782172cd8ba245c6e1ed009e54","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}},"12":{"name":"stdout","text":"Accuracy 0.976\n"},"13":{"data":{"image/png":"58c1149ef307b3d5acacb8d4facfc8ec29e81d22","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}},"14":{"data":{"image/png":"863378e1dd3a3caff8f5037e125c84d592c0d1b5","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":617},"needs_background":"light"}},"15":{"data":{"text/plain":"()"},"exec_count":14},"2":{"name":"stdout","text":"Accuracy 0.848\n"},"3":{"data":{"image/png":"a5e71ab0cca5b7a6aa06fd5dc5e3b9056b1f70c8","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}},"4":{"name":"stdout","text":"Accuracy 0.964\n"},"5":{"data":{"image/png":"df3dac9e4ea7189f2178710bf14b797ef6416a44","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}},"6":{"name":"stdout","text":"Accuracy 0.964\n"},"7":{"data":{"image/png":"bf90e273864e7cd8b0f77358f739e1a0fce0eeeb","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}},"8":{"name":"stdout","text":"Accuracy 0.97\n"},"9":{"data":{"image/png":"c3469213147f41240f9816c4be1b81a4ce1df8e3","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":605},"needs_background":"light"}}},"pos":22,"scrolled":true,"start":1557152495124,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152506475,"exec_count":15,"id":"b4cf97","input":"#Ex 4\n\nMatrices = build_model(4, print_loss=False,num_passes=500)\n\nprint(\"W1: \", Matrices['W1'], \"\\n\")\nprint(\"W2: \", Matrices['W2'], \"\\n\")\nprint(\"b1: \", Matrices['b1'], \"\\n\")\nprint(\"b2: \", Matrices['b2'], \"\\n\")","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"W1:  [[ 0.15445315  3.87927226 -4.91461429  3.95126325]\n [-0.69281964 -3.8358095  -3.43139998 -2.54825815]] \n\nW2:  [[-0.23977797  0.38597189]\n [-2.05025284  2.81043406]\n [-2.66262838  3.0824585 ]\n [-2.53486147  2.90466885]] \n\nb1:  [[-3.85511984 -4.63736833  2.86082529  1.82894707]] \n\nb2:  [[-0.08552787  0.08552787]] \n\n"}},"pos":23,"scrolled":true,"start":1557152506266,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152507227,"exec_count":16,"id":"ae30ae","input":"# Ex 5 - I feel like some actual lessons on how to do this would have been useful. I get marked down for my comments, but the ones in the given code are useless.\n#\n# def AccTest (model, inputdataX, inputdatay):\n#     acclist = []\n#     for i in range(1, 100, 1):\n#         acclist.append(accuracy(lambda x: predict(model,x)))\n\n\nX_test, y_test = generate_data(1000,rndm=903,noise=0.20)\n\nacclist = []\nfor i in range (len(modellist)):\n    print(\"Accuracy for model with {} hidden layers\".format(nlist[i]),accuracy1(lambda x: predict(modellist[i], x), X_test, y_test))\n    acclist.append(accuracy1(lambda x: predict(modellist[i], x), X_test, y_test))\n\nGeneralListPlot(nlist, acclist, \"n\", \"acc\")\nprint(\"Perfect Sqrt\")","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"Accuracy for model with 1 hidden layers 0.871\nAccuracy for model with 2 hidden layers 0.836\nAccuracy for model with 3 hidden layers 0.96\nAccuracy for model with 4 hidden layers 0.959\nAccuracy for model with 5 hidden layers 0.959\nAccuracy for model with 10 hidden layers 0.96\nAccuracy for model with 50 hidden layers 0.95\n"},"1":{"data":{"image/png":"c9be26c06f55a9babfbc1f57f481c7cb752d81c8","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":617},"needs_background":"light"}},"2":{"name":"stdout","text":"Perfect Sqrt\n"}},"pos":24,"start":1557152506484,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152507968,"exec_count":17,"id":"1d9379","input":"#Ex 6\n\nX_test1, y_test1 = generate_data(2000,rndm=903,noise=0.20)\n\nacclist = []\nfor i in range (len(modellist)):\n    print(\"Accuracy for model with {} hidden layers\".format(nlist[i]),accuracy1(lambda x: predict(modellist[i], x), X_test1, y_test1))\n    acclist.append(accuracy1(lambda x: predict(modellist[i], x), X_test1, y_test1))\n\nGeneralListPlot(nlist, acclist, \"n\", \"acc\")","kernel":"anaconda5","output":{"0":{"name":"stdout","text":"Accuracy for model with 1 hidden layers 0.8654999999999999\nAccuracy for model with 2 hidden layers 0.8475\nAccuracy for model with 3 hidden layers 0.968\nAccuracy for model with 4 hidden layers 0.964\nAccuracy for model with 5 hidden layers 0.964\nAccuracy for model with 10 hidden layers 0.9715\nAccuracy for model with 50 hidden layers 0.9605\n"},"1":{"data":{"image/png":"de35e7c5ba56add9dd1b4aecc6ff044aae73d7f2","text/plain":"<Figure size 720x576 with 1 Axes>"},"metadata":{"image/png":{"height":481,"width":617},"needs_background":"light"}},"2":{"data":{"text/plain":"()"},"exec_count":17}},"pos":25,"scrolled":true,"start":1557152507237,"state":"done","type":"cell"}
{"cell_type":"code","end":1557152507980,"exec_count":18,"id":"7617b1","input":"# Ex 7\n\n# Given that the y variable signifies the grouping, allowing y to be more than just 0 & 1 allows for more groups. There's probably a pred_func equivalent for that. Would also need extra Ws & bs\n#\n# Honestly, the whole code needs rewriting from scratch to make it work in a more general case. This is code written for a specific case and is not general enough\n#","kernel":"anaconda5","pos":26,"start":1557152507974,"state":"done","type":"cell"}
{"cell_type":"code","id":"3786a3","input":"\n","pos":28,"state":"done","type":"cell"}
{"cell_type":"code","id":"58dc47","input":"","pos":18,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"21148e","input":"### Model building\nThis example code uses the helpers above to run a neural network with 3 hidden layers and lots the decision boundary and the accuracy","pos":20,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"537df2","input":"## Train a neural network\nThe boundary between the red and blue areas can be identified using a neural network, as discussed in the lecture earlier. The following helper functions lay out the calculation needed to evaluate the loss function, its derivatives and to find the parameters of the network. ","pos":14,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"792a82","input":"# Lab 5: A 2-dimensional classification problem\nIn this session we will work with a set of data points in a 2-D plane. The task is to classify the points based on their coordinates and assign them to two different categories. The two categories are indicated with an integer with values 0 and 1. Each point on the plane belongs to a unique category.\n\nThe goal of the classification algorithm is to define a *prediction function* that predicts the category of a point based on its coordinates. The accuracy of our prediction is the ratio between the number of times we get the correct result and the total number of points.\n\nIn first part, we define the dataset and separate the categories in a simple way by drawing a straight line on the plane. \n\nIn the second part we use a neural network with one layer to find a more accurate solution\n\n### Import statements","pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"979663","input":"### Exercise 2: Train a linear model\nWrite a predLinear function that takes two arguments and separates the plane usign a straight line (a*x+b). The points above corresponds to category 0 and those below to category 1\n\nScan the parameters a and b and find the values that yield the highest accuracy. Print the values of a and b and plot the boundary graph. ","pos":12,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b8b0e4","input":"### Exercise 1. Optimise the constant prediction\nLoop over a value of C in the range (-1:1) in steps of 0.01 and find the value with the highest accuracy. Plot the decision boundary for this value","pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c0d182","input":"## Part 1: Prepare dataset and simple classification\n\n### Dataset preparation\nData points are generated using the *generate_data* function below. ","pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"eaa212","input":"### Exercise 3\nUse the code above to plot the boundaries for different sizes of the hidden layer (1, 2, 3, 4, 5, 10, 50). Evaluate the accuracy for each of the cases and report that as a table or as a graph\n\n### Exercise 4\nFor the case with a hidden layer of dimension 4, print the matrices $W_1$, $W_2$ and the bias vectors $b_1$ and $b_2$ that are obtained at the end of the training. Comment on their dimensionality. \n\n### Exercise 5\nGenerate a \"test data set\" with 1000 points, which is statistically independent from the training set by using a different random seed. Evaluate the accuracy as a function of the hidden layer dimension on this test data set. **Note* the test data set should not be used for training\n\n### Exercise 6\nRepeat the exercises above using a larger training set of 2000 events. In particular evaluate the efficiency using the test set defined in exercise 5\n\n### Exercise 7\nHow would you modify the code to classify elements with 3 or more categories? How would you modify the code to allow for more input parameters? Please provide a written description with code examples, but a full working code is not needed. The purpose of this exercise is for you to reflect on how to implement a more generic ANN, which we will use later in the course. \n\n### For PHY428. \n   * Generate test sets with different value of noise (0.4 and 0.6) and evaluate the efficiency using the model trained in exercise 5\n   * Optimise the minimisation of the loss function. Plot the value of the loss function vs the loop number and find a way to optimise the number of loops by stopping when a given a \n\n","pos":27,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f9f7c7","input":"### Helper functions\nThese two helper functions are used throughout the project. The input argument is a prediction function (*pred_func*). \n*pred_func* is a function that takes an array of points and returns an array of 0 and 1 based on the prediction. Examples are provided below.\n","pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ff68cf","input":"### Making a prediction and plotting a boundary \n","pos":7,"state":"done","type":"cell"}
{"id":0,"time":1557307981709,"type":"user"}
{"last_load":1557071348954,"type":"file"}